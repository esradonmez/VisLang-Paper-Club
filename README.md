# (Virtual) Machine Learning in Vision&Language Paper Club
A repository of papers in the field of Vision and Language.

## Joining Instructions ##
Every week, we will post a link next to the paper so that you can join at the time of the Meetup. The link will be posted here a few minutes before the start of the discussion.

During the discussion:
- Raise your (virtual) hand if you want to speak.
- Feel free to make comments or post your questions in the chat.

## Next meetup's paper ##

- [25. Jan 2022] (https://meet.google.com/mfd-zquk-wti) (Introductory reading) Shagun Uppal, Sarthak Bhagat, Devamanyu Hazarika, Navonil Majumder, Soujanya Poria, Roger Zimmermann, Amir Zadeh. Multimodal research in vision and language: A review of current and emerging trends, Information Fusion, Volume 77, 2022, Pages 149-171, ISSN 1566-2535 [Multimodal research in vision and language: A review of current andemerging trends](https://www.sciencedirect.com/science/article/pii/S1566253521001512). 

## Supplementary material ##

For those new to machine learning, these are some recommended reading material:

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). [Deep learning.](http://www.deeplearningbook.org/) MIT press.

- Goldberg, Y. (2016). [A primer on neural network models for natural language processing.](http://u.cs.biu.ac.il/~yogo/nnlp.pdf) Journal of Artificial Intelligence Research, 57, 345-420.

- Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., & Yu, P. S. (2019). [A comprehensive survey on graph neural networks.](https://arxiv.org/pdf/1901.00596.pdf) arXiv preprint arXiv:1901.00596.

Transformer-related resources:

- [The illustrated transformer](http://jalammar.github.io/illustrated-transformer/)

- [The annotated transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#attention)

- [Embedding layers in BERT, explained](https://medium.com/@_init_/why-bert-has-3-embedding-layers-and-their-implementation-details-9c261108e28a)

- Examples of BERT: [sentiment analysis](https://github.com/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb) and [feature extraction from BERT](https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b)

